{"cells":[{"attachments":{},"cell_type":"markdown","id":"6fcbaefa-ded0-43e0-8a6a-63fc89f4478b","metadata":{"language":"python"},"source":"# NLP with Hugging Face and Transformers"},{"attachments":{},"cell_type":"markdown","id":"58047e43-055b-4a37-a97b-75373ae1e68a","metadata":{"language":"python"},"source":"Hugging Face is an open-source framework and platform that specializes in Natural Language Processing (NLP) and machine learning. It's known for its Transformers library, which provides a wide range of pre-trained models for tasks like text classification, translation, summarization, and more. Hugging Face makes it easy for developers to leverage these powerful models and integrate them into various applications."},{"attachments":{},"cell_type":"markdown","id":"6c3f2a76-ef51-4459-9f4f-04f78b4867b0","metadata":{"language":"python"},"source":"## Text Classification\nText classification is a fundamental task in natural language processing (NLP) that involves categorizing or assigning labels to text based on its content. The goal is to classify the input text into one or more predefined categories or classes. "},{"attachments":{},"cell_type":"markdown","id":"1cfb94c6-ecf8-4427-ab86-c3deecc0d1d1","metadata":{"language":"python"},"source":"Example of a comment from a customer to do perform text classification using Hugging Face Transformers"},{"cell_type":"code","execution_count":3,"id":"ed30558b-c7e0-4eae-92f7-7ac97acf039d","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:18:47.458895Z","iopub.status.busy":"2024-07-30T09:18:47.458372Z","iopub.status.idle":"2024-07-30T09:18:47.464441Z","shell.execute_reply":"2024-07-30T09:18:47.463818Z","shell.execute_reply.started":"2024-07-30T09:18:47.458851Z"},"language":"python","trusted":true},"outputs":[],"source":"text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\nfrom your online store in Germany. Unfortunately, when I opened the package, \\\nI discovered to my horror that I had been sent an action figure of Megatron \\\ninstead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\ndilemma. To resolve the issue, I demand an exchange of Megatron for the \\\nOptimus Prime figure I ordered. Enclosed are copies of my records concerning \\\nthis purchase. I expect to hear from you soon. Sincerely, John.\"\"\""},{"attachments":{},"cell_type":"markdown","id":"33b84952-4b4a-4d27-8d90-0f461cf19791","metadata":{"language":"python"},"source":"Create the text classification pipeline"},{"cell_type":"code","execution_count":4,"id":"32520253-5cac-4d9a-b270-4fa32ff90a09","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:19:52.059826Z","iopub.status.busy":"2024-07-30T09:19:52.059284Z","iopub.status.idle":"2024-07-30T09:19:57.774876Z","shell.execute_reply":"2024-07-30T09:19:57.774150Z","shell.execute_reply.started":"2024-07-30T09:19:52.059800Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n"}],"source":"from transformers import pipeline\nclassifier = pipeline(\"text-classification\")"},{"attachments":{},"cell_type":"markdown","id":"62bbe96f-46f7-4d97-bcd4-fba03ab9cab8","metadata":{"language":"python"},"source":"Let’s make some predictions"},{"cell_type":"code","execution_count":5,"id":"012dcc09-564c-4384-a41f-ece53a7a9376","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:20:02.862190Z","iopub.status.busy":"2024-07-30T09:20:02.861521Z","iopub.status.idle":"2024-07-30T09:20:03.094088Z","shell.execute_reply":"2024-07-30T09:20:03.090118Z","shell.execute_reply.started":"2024-07-30T09:20:02.862008Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NEGATIVE</td>\n      <td>0.888494</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      label     score\n0  NEGATIVE  0.888494"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"import pandas as pd\noutputs = classifier(text)\npd.DataFrame(outputs)"},{"attachments":{},"cell_type":"markdown","id":"60060ce9-aa5b-4b41-b374-daaa14eef94f","metadata":{"language":"python"},"source":"## Named Entity Recognition"},{"attachments":{},"cell_type":"markdown","id":"41cae6fc-d195-42c2-bb47-2fbffe03c71a","metadata":{"language":"python"},"source":"In NLP, real-world objects like products, places, and people are called named entities, and extracting them from text is called named entity recognition (NER). Let's take a look at NER by loading the corresponding pipeline and feeding our customer review to it."},{"cell_type":"code","execution_count":6,"id":"189c4d8a-b0c5-4c57-860a-1b39ea39bfec","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:20:46.571414Z","iopub.status.busy":"2024-07-30T09:20:46.570467Z","iopub.status.idle":"2024-07-30T09:20:47.619083Z","shell.execute_reply":"2024-07-30T09:20:47.618476Z","shell.execute_reply.started":"2024-07-30T09:20:46.571379Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nSome weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity_group</th>\n      <th>score</th>\n      <th>word</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ORG</td>\n      <td>0.866123</td>\n      <td>Amazon</td>\n      <td>5</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MISC</td>\n      <td>0.991707</td>\n      <td>Optimus Prime</td>\n      <td>36</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOC</td>\n      <td>0.999765</td>\n      <td>Germany</td>\n      <td>90</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MISC</td>\n      <td>0.580447</td>\n      <td>Mega</td>\n      <td>208</td>\n      <td>212</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PER</td>\n      <td>0.502781</td>\n      <td>##tron</td>\n      <td>212</td>\n      <td>216</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ORG</td>\n      <td>0.683059</td>\n      <td>Decept</td>\n      <td>253</td>\n      <td>259</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MISC</td>\n      <td>0.509665</td>\n      <td>##icons</td>\n      <td>259</td>\n      <td>264</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MISC</td>\n      <td>0.786567</td>\n      <td>Megatron</td>\n      <td>350</td>\n      <td>358</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>MISC</td>\n      <td>0.988930</td>\n      <td>Optimus Prime</td>\n      <td>367</td>\n      <td>380</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PER</td>\n      <td>0.992709</td>\n      <td>John</td>\n      <td>502</td>\n      <td>506</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"  entity_group     score           word  start  end\n0          ORG  0.866123         Amazon      5   11\n1         MISC  0.991707  Optimus Prime     36   49\n2          LOC  0.999765        Germany     90   97\n3         MISC  0.580447           Mega    208  212\n4          PER  0.502781         ##tron    212  216\n5          ORG  0.683059         Decept    253  259\n6         MISC  0.509665        ##icons    259  264\n7         MISC  0.786567       Megatron    350  358\n8         MISC  0.988930  Optimus Prime    367  380\n9          PER  0.992709           John    502  506"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\noutputs = ner_tagger(text)\npd.DataFrame(outputs)"},{"attachments":{},"cell_type":"markdown","id":"ce31dd4d-c469-4f1d-9e52-4241a296ed18","metadata":{"language":"python"},"source":"As you can see, the pipeline found all of the entities and assigned them a category such as ORG (organization) for the text."},{"attachments":{},"cell_type":"markdown","id":"a130f133-8e8b-46c7-8744-df4f8b6a5c19","metadata":{"language":"python"},"source":"## Question Answering"},{"attachments":{},"cell_type":"markdown","id":"198ea297-4fcd-43a4-b495-86b449fbcf0b","metadata":{"language":"python"},"source":"In question answering, we give the model a passage of text known as the context, as well as a question whose answer we want to extract. The model then returns the text span associated with the answer. Let's take a look at what happens if we ask a specific question about customer feedback:"},{"cell_type":"code","execution_count":7,"id":"a549431a-3585-4d00-bc11-4cd3b63a67ab","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:21:05.369253Z","iopub.status.busy":"2024-07-30T09:21:05.368887Z","iopub.status.idle":"2024-07-30T09:21:05.761030Z","shell.execute_reply":"2024-07-30T09:21:05.760427Z","shell.execute_reply.started":"2024-07-30T09:21:05.369223Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>start</th>\n      <th>end</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.627353</td>\n      <td>335</td>\n      <td>358</td>\n      <td>an exchange of Megatron</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      score  start  end                   answer\n0  0.627353    335  358  an exchange of Megatron"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"reader = pipeline(\"question-answering\")\nquestion = \"What does the customer want?\"\noutputs = reader(question=question, context=text)\npd.DataFrame([outputs])"},{"attachments":{},"cell_type":"markdown","id":"cd9bc2d1-1327-442a-812b-241e11dffa18","metadata":{"language":"python"},"source":"You can see the answer. Note that the pipeline also gives us the start and end integers corresponding to the character indices where the answer range is located."},{"attachments":{},"cell_type":"markdown","id":"b13ab947-3d5e-4f8f-8739-56668f289058","metadata":{"language":"python"},"source":"## Summarization"},{"attachments":{},"cell_type":"markdown","id":"63e91d13-b60f-417b-9434-cea96eb7cace","metadata":{"language":"python"},"source":"With text summarization, you can take a long text as input and generate a short version. Let's take a look at this technique."},{"cell_type":"code","execution_count":12,"id":"b791e89f-0e31-4ada-9d63-1e868a498a51","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:21:19.655514Z","iopub.status.busy":"2024-07-30T09:21:19.655067Z","iopub.status.idle":"2024-07-30T09:21:27.427644Z","shell.execute_reply":"2024-07-30T09:21:27.427015Z","shell.execute_reply.started":"2024-07-30T09:21:19.655486Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nYour min_length=56 must be inferior than your max_length=45.\n/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1283: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (45). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n  warnings.warn(\n"},{"name":"stdout","output_type":"stream","text":" John ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when he opened the package, he discovered to his horror that he had been sent an action figure of Megatron instead. As a\n"}],"source":"summarizer = pipeline(\"summarization\")\noutputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\nprint(outputs[0]['summary_text'])"},{"attachments":{},"cell_type":"markdown","id":"963720f6-a7a8-42ba-ab0f-63fab6790e5d","metadata":{"language":"python"},"source":"As you can see that the model was able to capture the essence of the problem and correctly identify."},{"attachments":{},"cell_type":"markdown","id":"5e59c139-3d98-473b-bcf8-c45e7d1a1072","metadata":{"language":"python"},"source":"## Translation"},{"attachments":{},"cell_type":"markdown","id":"71cedc35-aeeb-4fdc-aea6-342a88bfdfce","metadata":{"language":"python"},"source":"Translation, like summarization, is a task whose output is generated text. To translate an English text to German, let's use a translation."},{"cell_type":"code","execution_count":13,"id":"a71a2f7e-1ba1-4b34-b989-c14e495c4273","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:21:54.121980Z","iopub.status.busy":"2024-07-30T09:21:54.120421Z","iopub.status.idle":"2024-07-30T09:22:03.484016Z","shell.execute_reply":"2024-07-30T09:22:03.483299Z","shell.execute_reply.started":"2024-07-30T09:21:54.121883Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n"},{"name":"stdout","output_type":"stream","text":"Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime Action Figur von Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich hoffe, Sie können mein Dilemma verstehen. Um das Problem zu lösen, Ich fordere einen Austausch von Megatron für die Optimus Prime Figur habe ich bestellt. Eingeschlossen sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, von Ihnen bald zu hören. Aufrichtig, John.\n"}],"source":"translator = pipeline(\"translation_en_to_de\", \n                      model=\"Helsinki-NLP/opus-mt-en-de\")\noutputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\nprint(outputs[0]['translation_text'])"},{"attachments":{},"cell_type":"markdown","id":"dc030f23-f0c4-4f0b-9d0b-274c1d2c5d80","metadata":{"language":"python"},"source":"As you can see translation isn't bad. You can find models for thousands of language pairs on the Hugging Face Hub."},{"attachments":{},"cell_type":"markdown","id":"a2c8b679-3eee-4892-9a85-7ca9e768d0f1","metadata":{"language":"python"},"source":"## Text Generation"},{"attachments":{},"cell_type":"markdown","id":"0313a066-91c8-4a02-9ff7-65f9da8d1b31","metadata":{"language":"python"},"source":"Assume you want to be able to respond to customer feedback more quickly by having access to an autocomplete function. This is possible with a text generation model:"},{"cell_type":"code","execution_count":19,"id":"db905361-466d-46b2-b15a-08ab6ec56607","metadata":{"execution":{"iopub.execute_input":"2024-07-30T09:25:44.455972Z","iopub.status.busy":"2024-07-30T09:25:44.455581Z","iopub.status.idle":"2024-07-30T09:25:49.709155Z","shell.execute_reply":"2024-07-30T09:25:49.708544Z","shell.execute_reply.started":"2024-07-30T09:25:44.455936Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"},{"name":"stdout","output_type":"stream","text":"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, John.\n\nCustomer service response:\nDear John, I am sorry to hear that your order was mixed up. The order was shipped and your order shipped, however I must reiterate: this is not the case (the order was ordered in Japan, not in Germany, according to orders.com). I am sorry about this. As I said in my reply, with that kind of information, I'm sorry what happened to you and I have reached out to you sincerely\n"}],"source":"generator = pipeline(\"text-generation\")\nresponse = \"Dear John, I am sorry to hear that your order was mixed up.\"\nprompt = text + \"\\n\\nCustomer service response:\\n\" + response\noutputs = generator(prompt, max_length=200)\nprint(outputs[0]['generated_text'])"},{"attachments":{},"cell_type":"markdown","id":"355a8efd-e0bd-4ca0-b673-0d42c44088a1","metadata":{"language":"python"},"source":"You can generate a response like this to calm the customer."},{"attachments":{},"cell_type":"markdown","id":"14e4fd32-f3b3-4ac9-968c-6c003f27160d","metadata":{"language":"python"},"source":"Now that you've seen several great applications of transformer models. All the models we use in this section are public and have already been fine-tuned for the task at hand. But in general, you can fine-tune models on your own data."},{"cell_type":"code","execution_count":null,"id":"cc1c94bd-aed1-4cd6-86b3-e8a4e8fac050","metadata":{"language":"python","trusted":true},"outputs":[],"source":""}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"d82f0eed-b7ed-49ef-87f7-106f7fa21a73","defaultDatabase":"database_c229c"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}